# Copyright 2020 Cerebras Systems.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Params for FC MNIST model
description: "FC-MNIST base model params"

train_input:
    shuffle: True
    shuffle_buffer_size : 10000
    augment_data: True
    dataset_path: 'data' # Place to store data

    num_parallel_calls: 0   # 0 means AUTOTUNE
    # num_parallel_reads: 16
    train_test_split: 0.79
    num_classes: 7
    image_size: 96 #128
    dataset: "IR_dataset"
    IR_channel_level: 19 # up to 19 
    noise_variance: 0

vit:
  vit_base_patch8_384:
    image_size: 384
    patch_size: 8
    d_model: 768
    n_heads: 12
    n_layers: 12
    normalization: vit
    distilled: false
  vit_tiny_patch16_384:
    image_size: 384
    patch_size: 16
    d_model: 192
    n_heads: 3
    n_layers: 12
    normalization: vit
    distilled: false
  vit_small_patch16_384:
    image_size: 384
    patch_size: 16
    d_model: 384
    n_heads: 6
    n_layers: 12
    normalization: vit
    distilled: false
  vit_base_patch16_384:
    image_size: 384
    patch_size: 16
    d_model: 768
    n_heads: 12
    n_layers: 12
    normalization: vit
    distilled: false
  vit_large_patch16_384:
    image_size: 384
    patch_size: 16
    d_model: 1024
    n_heads: 16
    n_layers: 24
    normalization: vit
  vit_small_patch32_384:
    image_size: 384
    patch_size: 32
    d_model: 384
    n_heads: 6
    n_layers: 12
    normalization: vit
    distilled: false
  vit_base_patch32_384:
    image_size: 384
    patch_size: 32
    d_model: 768
    n_heads: 12
    n_layers: 12
    normalization: vit
  vit_large_patch32_384:
    image_size: 384
    patch_size: 32
    d_model: 1024
    n_heads: 16
    n_layers: 24
    normalization: vit


model:
    backbone: "vit_large_patch16_384"
    decoder:
        name: "mask_transformer"
        drop_path_rate: 0.0
        dropout: 0.1
        n_layers: 2
    n_cls: 7


optimizer:
    lr: 0.001
    optimizer_type: 'adam' # {'sgd', 'momentum', 'adam', 'adamw'}
    weight_decay_rate: 5e-5
    epsilon: 1e-6
    max_gradient_norm: 1.0
    disable_lr_steps_reset: True
    learning_rate:
        - steps: 10000
          scheduler: 'Linear'
          initial_learning_rate: 0.0
          end_learning_rate: 0.0001
        - scheduler: 'Linear'
          initial_learning_rate: 0.0001
          end_learning_rate: 0.0
          steps: 1000000
    loss_scaling_factor: 'dynamic'


runconfig:
    model_type: "Segmenter"
    logs: './checkpoints/Segmenter'
    pretrained: False
    pretrained_from_DDP: True
    epochs: 100000
    steps_per_epoch: 32
    train_batch_size: 32
    eval_batch_size: 32
    save_summary_epoch: 100
    save_checkpoints_epoch: 100
    keep_checkpoint_max: 2
    model_dir: 'model_dir'
    cs_ip:
    multireplica: False
    mode: 'train'
    eval_steps: 100
    valid: True
    valid_only: False
    valid_every: 20
    model_path: "checkpoints"
    save_as_new: False
    world_size: 1
